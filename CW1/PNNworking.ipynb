{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, labels_train), (x_test, labels_test) = mnist.load_data()\n",
    "\n",
    "# x_train is the handstroke image\n",
    "# labels_train are according labels =>array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # x_train[1, :].shape # 28*28*1\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.image as img\n",
    "# myimage = img.imread(\"xxx.jpg\")\n",
    "\n",
    "# # plt.imshow(x_train[1,:].reshape(28,28), cmap=plt.get_cmap('gray'))\n",
    "# # plt.imshow(myimage[:, :, 1], cmap=plt.get_cmap('gray'))\n",
    "# # x_test.shape\n",
    "\n",
    "# mytest = np.zeros((1, 28, 28, 1))\n",
    "# mytest[0, :, :, 0] = myimage[:, :, 1]\n",
    "# myoutput=net.predict(mytest)\n",
    "# myoutput\n",
    "# mylabels_predicted=np.argmax(myoutput, axis=1)\n",
    "# mylabels_predicted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The MNIST images are stored in the form of integers with values in the range [0,255]. \n",
    "# To convert to floating-point numbers in the range [0,1]:\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To define the output that the network should produce (integers 0 to 9) in response to each sample (a one hot encoding):\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(labels_train, 10)\n",
    "y_test = to_categorical(labels_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DENSE LAYER --> If the data is to be used as input to a dense layer, then it should be reshaped into \n",
    "# a matrix where each row is a sample:\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVOLUTIONAL LAYER --> If the data is to be used as input to a convolutional layer, then it should be reshaped into \n",
    "# a four-dimensional matrix where the first dimension corresponds to the number of exemplars, \n",
    "# the second and third dimensions correspond to the width and height of each image, and the fourth\n",
    "# dimension corresponds to the number of colour channels in each image:\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-509d63035616>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# load training & testing dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0memnist_x_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0memnist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"dataset\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0memnist_x_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0memnist_x_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0memnist_x_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0memnist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"dataset\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0memnist_x_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0memnist_x_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "from scipy import io as spio\n",
    "emnist = spio.loadmat(\"emnist-digits.mat\")\n",
    "\n",
    "# load training & testing dataset\n",
    "emnist_x_train = emnist[\"dataset\"][0][0][0][0][0][0]\n",
    "emnist_x_train = emnist_x_train.astype(np.float32)\n",
    "emnist_x_test = emnist[\"dataset\"][0][0][1][0][0][0]\n",
    "emnist_x_test = emnist_x_test.astype(np.float32)\n",
    "\n",
    "# load training & testing labels\n",
    "emnist_y_train = emnist[\"dataset\"][0][0][0][0][0][1]\n",
    "emnist_y_test = emnist[\"dataset\"][0][0][1][0][0][1]\n",
    "\n",
    "# store labels for visualization\n",
    "emnist_train_labels = emnist_y_train\n",
    "emnist_test_labels = emnist_y_test\n",
    "\n",
    "print(emnist_x_train.shape, emnist_x_test.shape)\n",
    "# (240000, 784) (40000, 784)\n",
    "print(emnist_y_train.shape, emnist_y_test.shape)\n",
    "# (240000, 1) (40000, 1)\n",
    "print(emnist_train_labels.shape, emnist_test_labels.shape)\n",
    "# (240000, 1) (40000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize\n",
    "emnist_x_train /= 255\n",
    "emnist_x_test /= 255\n",
    "\n",
    "from keras.utils import np_utils\n",
    "# reshape using matlab order\n",
    "emnist_x_train = emnist_x_train.reshape(emnist_x_train.shape[0], 1, 28, 28, order=\"A\")\n",
    "emnist_x_test = emnist_x_test.reshape(emnist_x_test.shape[0], 1, 28, 28, order=\"A\")\n",
    "emnist_x_train.shape\n",
    "# (240000, 1, 28, 28)\n",
    "emnist_y_train.shape\n",
    "# (240000, 1)\n",
    "\n",
    "# labels should be one hot encoded\n",
    "emnist_y_train = keras.utils.np_utils.to_categorical(emnist_y_train, 10)\n",
    "emnist_y_test = keras.utils.np_utils.to_categorical(emnist_y_test, 10)\n",
    "\n",
    "emnist_y_train.shape\n",
    "# (240000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(\n",
    "    nrows=5,\n",
    "    ncols=5,\n",
    "    sharex='all',\n",
    "    sharey='all', )\n",
    "ax = ax.flatten()\n",
    "\n",
    "# --- Choose one of the two start ---\n",
    "for i in range(25):\n",
    "    img = x_train[i].reshape(28, 28)\n",
    "    ax[i].imshow(img, cmap='Greys', interpolation='nearest')\n",
    "\n",
    "    \n",
    "# indexs = np.where(labels_train == 7)\n",
    "# for i in range(25):\n",
    "#     img = x_train[indexs[0][i]].reshape(28, 28)\n",
    "#     ax[i].imshow(img, cmap='Greys', interpolation='nearest')\n",
    "# --- Choose one of the two end --- \n",
    "    \n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画一个直方图,看看数据集中各个数字的数据量\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for i in range(10):\n",
    "    x = i\n",
    "    y = np.sum(labels_train == i)\n",
    "    X.append(x)\n",
    "    Y.append(y)\n",
    "    plt.text(x, y, '%s' % y, ha='center', va= 'bottom')\n",
    "\n",
    "plt.bar(X, Y, facecolor='#9999ff', edgecolor='white')\n",
    "plt.xticks(X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a Neural Network\n",
    "define its architecture (the number and types of layers, and their interconnectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1 -- 3 layer MLP network called “net”\n",
    "# you can define a sequence of layers, it is assumed that the output of one layer provides the input to the next. \n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "net = Sequential()\n",
    "net.add(Dense(800, activation='relu', input_shape=(784,)))\n",
    "net.add(Dense(400, activation='relu'))\n",
    "net.add(Dense(10, activation='softmax'))\n",
    "# activation functions -- https://keras.io/activations/\n",
    "# different types of layers that can be used -- https://keras.io/layers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to build a simple CNN using convolutional, maxpooling, as well as dense layers (and with dropout for one layer):\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten,Dropout\n",
    "net = Sequential()\n",
    "net.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu',\n",
    "input_shape=(28,28,1)))\n",
    "net.add(MaxPool2D(pool_size=(2, 2)))\n",
    "net.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "net.add(MaxPool2D(pool_size=(2, 2)))\n",
    "net.add(Flatten())\n",
    "net.add(Dense(256, activation='relu'))\n",
    "net.add(Dropout(rate=0.5))\n",
    "net.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2 -- 3 layer MLP network (equivalent to that built using method 1)\n",
    "# you can name the output of each layer, and to use these name to define where each layer receives input from. \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "input_img = Input(shape=(784,)) # define a placeholder for the input data\n",
    "x = Dense(800, activation='relu')(input_img)\n",
    "y = Dense(400, activation='relu')(x)\n",
    "z = Dense(10, activation='softmax')(y)\n",
    "net = Model(input_img, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method allows the construction of networks in which one layer supplies input to multiple other layers, \n",
    "# and/or one layer receives input from multiple other layers, e.g.:\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.layers import concatenate\n",
    "input_img = Input(shape=(784,)) # define a placeholder for the input data\n",
    "x = Dense(800, activation='relu')(input_img)\n",
    "y1= Dense(100, activation='tanh')(x)\n",
    "y2= Dense(200, activation='relu')(x)\n",
    "y = concatenate([y1, y2])\n",
    "z = Dense(10, activation='softmax')(y)\n",
    "net = Model(input_img, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, the variable name used for one layer can be reused (overwritten) by another layer. For\n",
    "# example, a simple CNN equivalent to that built with method 1, can be constructed like so:\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten,Dropout, Input\n",
    "inputs = Input(shape=x_train.shape[1:])\n",
    "x = Conv2D(filters=32, kernel_size=(5,5), activation='relu')(inputs)\n",
    "x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "x = Conv2D(filters=32, kernel_size=(3,3), activation='relu')(x)\n",
    "x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "outputs = Dense(10, activation='softmax')(x)\n",
    "net = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whichever method is used to define a network, a textual description of its structure can be obtained using:\n",
    "net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or an image can be obtained using:\n",
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(net, to_file='network_structure.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is achieved by first compiling the network, at this stage the cost function (https://keras.io/losses/) and \n",
    "# the optimizer (https://keras.io/optimizers/) that is to be used for training is defined. \n",
    "# Next the training is performed using the function fit. This function needs to be supplied with \n",
    "# the training data, and optionally, validation data, and other parameters such as \n",
    "# the number of epochs and the batch size to be used, e.g.:\n",
    "net.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "history = net.fit(x_train, y_train,\n",
    "validation_data=(x_test, y_test), epochs=20, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The history variable returned by the fit function can be used to produce a plot showing the\n",
    "# change in the cost function during training:\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='training loss')\n",
    "plt.plot(history.history['val_loss'], label='validation loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A trained network can be saved to disk using:\n",
    "net.save(\"network_for_mnist.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A saved model can be reloaded using:\n",
    "from tensorflow.keras.models import load_model\n",
    "net=load_model(\"network_for_mnist.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The performance of the trained network can be tested, for example, by finding the outputs that\n",
    "# it produces to the testing data, and comparing these to the true category labels:\n",
    "import numpy as np\n",
    "outputs=net.predict(x_test)\n",
    "labels_predicted=np.argmax(outputs, axis=1)\n",
    "misclassified=sum(labels_predicted!=labels_test)\n",
    "print('Percentage misclassified = ',100*misclassified/labels_test.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To show the outputs a network produces for a few specific exemplars:\n",
    "plt.figure(figsize=(8, 2))\n",
    "for i in range(0,8):\n",
    "    ax=plt.subplot(2,8,i+1)\n",
    "    plt.imshow(x_test[i,:].reshape(28,28), cmap=plt.get_cmap('gray_r'))\n",
    "    plt.title(labels_test[i])\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "for i in range(0,8):\n",
    "#     output = net.predict(x_test[i,:].reshape(1, 784)) #if MLP\n",
    "    output = net.predict(x_test[i,:].reshape(1, 28,28,1)) #if CNN\n",
    "    output=output[0,0:]\n",
    "    plt.subplot(2,8,8+i+1)\n",
    "    plt.bar(np.arange(10.),output)\n",
    "    plt.title(np.argmax(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "#load .h5 file of arbitrary name for testing (last if more than one)\n",
    "print(os.getcwd())\n",
    "for file in os.listdir(os.getcwd()):\n",
    "    if file.endswith(\".h5\"):\n",
    "        print(file)\n",
    "        net=load_model(file)\n",
    "net.summary()\n",
    "\n",
    "#determine what type of network this is\n",
    "conf=net.layers[0].get_config()\n",
    "inshape=conf['batch_input_shape']\n",
    "if inshape[1]==28:\n",
    "    netType='CNN'\n",
    "else:\n",
    "    netType='MLP'\n",
    "    \n",
    "#test with MNIST data\n",
    "# from tensorflow.keras.datasets import mnist\n",
    "# (x_train, labels_train), (x_test, labels_test) = mnist.load_data()\n",
    "# x_test = x_test.astype('float32')\n",
    "# x_test /= 255\n",
    "if netType in ['MLP']:\n",
    "    x_test = x_test.reshape(10000, 784)\n",
    "else:\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "outputs=net.predict(x_test)\n",
    "\n",
    "# Returns the indices of the maximum values along an axis.\n",
    "labels_predicted=np.argmax(outputs, axis=1)\n",
    "correct_classified=sum(labels_predicted==labels_test)\n",
    "print('Percentage correctly classified MNIST= ',100*correct_classified/labels_test.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
